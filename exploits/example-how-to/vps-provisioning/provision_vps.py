import json
import os
import time
import yaml
from typing import Dict, Any, List

# Requirements: pip install pyyaml python-digitalocean paramiko boto3
# WARNING: Secure credentials! Use environment vars or secrets manager in production.
# For AWS key creation, script will save private key if new.

try:
    import digitalocean
except ImportError:
    print("pip install python-digitalocean")
    exit(1)

try:
    import boto3
    from botocore.exceptions import ClientError
except ImportError:
    print("pip install boto3")
    exit(1)

try:
    import paramiko
except ImportError:
    print("pip install paramiko")
    exit(1)


def load_config(config_path: str) -> Dict[str, Any]:
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Config file not found: {config_path}")
    with open(config_path, 'r') as f:
        if config_path.endswith(('.yaml', '.yml')):
            return yaml.safe_load(f)
        elif config_path.endswith('.json'):
            return json.load(f)
        else:
            raise ValueError("Config must be YAML or JSON")


def deploy_digitalocean(config: Dict[str, Any]) -> str:
    token = config['credentials']['token']
    manager = digitalocean.Manager(token=token)
    droplet = digitalocean.Droplet(
        token=token,
        name=config['instance']['name'],
        region=config['instance']['region'],
        image=config['instance']['image'],
        size_slug=config['instance']['size'],
        ssh_keys=[config['instance']['ssh_pub_key_id']],  # Key ID
        backups=False
    )
    droplet.create()
    print(f"Creating droplet {droplet.name}...")
    # Wait for creation
    while droplet.get_status() != 'active':
        time.sleep(10)
        droplet.load()
    ip_address = droplet.ip_address
    print(f"Droplet IP: {ip_address}")
    # Firewall
    if 'networking' in config and 'firewall_rules' in config['networking']:
        inbound_rules: List = []
        for rule in config['networking']['firewall_rules']:
            ports_list = rule['ports'] if isinstance(rule['ports'], list) else [rule['ports']]
            for p in ports_list:
                inbound_rules.append(
                    digitalocean.InboundRule(
                        protocol=rule['protocol'],
                        ports=str(p),
                        sources=digitalocean.Sources(addresses=[rule['sources']])
                    )
                )
        firewall = digitalocean.Firewall(
            token=token,
            name=f"{droplet.name}-firewall",
            inbound_rules=inbound_rules,
            outbound_rules=[digitalocean.OutboundRule(protocol="all", ports="all", destinations=digitalocean.Destinations(addresses=["0.0.0.0/0"]))],
            droplet_ids=[droplet.id]
        )
        firewall.create()
        print("Firewall set up.")
    return ip_address


def deploy_aws(config: Dict[str, Any]) -> str:
    creds = config['credentials']
    instance_cfg = config['instance']
    region = instance_cfg.get('region', 'us-east-1')
    ec2 = boto3.client('ec2', aws_access_key_id=creds['access_key'], aws_secret_access_key=creds['secret_key'], region_name=region)
    key_name = instance_cfg.get('key_name', 'vps-key')
    private_key_path = instance_cfg['ssh_key']
    # Handle key pair
    try:
        ec2.describe_key_pairs(KeyNames=[key_name])
        print(f"Using existing key pair: {key_name}")
    except ClientError as e:
        if 'InvalidKeyPair.NotFound' in str(e):
            key_pair = ec2.create_key_pair(KeyName=key_name)
            with open(private_key_path, 'w') as f:
                f.write(key_pair['KeyMaterial'])
            os.chmod(private_key_path, 0o600)
            print(f"Created new key pair and saved private key to {private_key_path}")
        else:
            raise
    # Security group
    sg_name = f"{instance_cfg['name']}-sg"
    try:
        sg_resp = ec2.create_security_group(GroupName=sg_name, Description="VPS SG")
        sg_id = sg_resp['GroupId']
    except ClientError as e:
        if 'InvalidGroup.Duplicate' in str(e):
            resp = ec2.describe_security_groups(Filters=[{'Name': 'group-name', 'Values': [sg_name]}])
            sg_id = resp['SecurityGroups'][0]['GroupId']
        else:
            raise
    # Authorize ingress
    if 'networking' in config and 'firewall_rules' in config['networking']:
        ip_perms = []
        for rule in config['networking']['firewall_rules']:
            ports_list = rule['ports'] if isinstance(rule['ports'], list) else [rule['ports']]
            for p in ports_list:
                ip_perms.append({
                    'IpProtocol': rule['protocol'],
                    'FromPort': int(p),
                    'ToPort': int(p),
                    'IpRanges': [{'CidrIp': rule['sources']}]
                })
        ec2.authorize_security_group_ingress(GroupId=sg_id, IpPermissions=ip_perms)
        print(f"Security rules added to {sg_id}")
    # Launch instance
    instances = ec2.run_instances(
        ImageId=instance_cfg['image'],
        MinCount=1, MaxCount=1,
        InstanceType=instance_cfg['size'],
        KeyName=key_name,
        SecurityGroupIds=[sg_id]
    )
    instance_id = instances['Instances'][0]['InstanceId']
    print(f"Launching instance {instance_id}...")
    waiter = ec2.get_waiter('instance_running')
    waiter.wait(InstanceIds=[instance_id])
    resp = ec2.describe_instances(InstanceIds=[instance_id])
    ip_address = resp['Reservations'][0]['Instances'][0]['PublicIpAddress']
    print(f"Instance IP: {ip_address}")
    return ip_address


def setup_vps_via_ssh(ip_address: str, config: Dict[str, Any]):
    private_key_path = config['instance']['ssh_key']
    if not os.path.exists(private_key_path):
        raise FileNotFoundError(f"Private key not found: {private_key_path}")
    key = paramiko.RSAKey.from_private_key_file(private_key_path)
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    print(f"SSH to {ip_address}...")
    client.connect(hostname=ip_address, username='ubuntu', pkey=key, timeout=30)
    commands = []
    # Base update
    commands.append('sudo apt update -y && sudo apt upgrade -y')
    # Provisions
    provisions = config.get('provision', [])
    if 'docker' in provisions:
        # Uninstall conflicting
        commands.append('for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg -y || true; done')
        # Repo setup
        commands.append('sudo apt-get install ca-certificates curl gnupg -y')
        commands.append('sudo install -m 0755 -d /etc/apt/keyrings')
        commands.append('sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc')
        commands.append('sudo chmod a+r /etc/apt/keyrings/docker.asc')
        commands.append(r'''echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null''')
        commands.append('sudo apt-get update')
        # Install
        commands.append('sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y')
        # Verify
        commands.append('sudo docker run --rm hello-world')
        # Post-install
        commands.append('sudo usermod -aG docker ubuntu')
        commands.append('sudo systemctl enable --now docker')
        print("Docker provisioned. Reconnect SSH for non-sudo docker access.")
    if 'podman' in provisions:
        commands.append('sudo apt-get install podman -y')
    if 'python' in provisions:
        commands.append('sudo apt-get install python3 python3-pip python3-venv -y')
    # Tools
    if 'tools_to_install' in config:
        tools = ' '.join(config['tools_to_install'])
        commands.append(f'sudo apt-get install -y {tools}')
    # Clones
    if 'repos_to_clone' in config:
        for repo in config['repos_to_clone']:
            repo_name = repo.split('/')[-1].rstrip('.git')
            commands.append(f'git clone {repo} /home/ubuntu/{repo_name}')
    # Execute
    for cmd in commands:
        print(f"Exec: {cmd}")
        stdin, stdout, stderr = client.exec_command(cmd)
        out = stdout.read().decode().strip()
        err = stderr.read().decode().strip()
        if out: print(out)
        if err: print(f"ERR: {err}")
        if stderr.channel.recv_exit_status() != 0:
            print(f"Command failed: {cmd}")
    client.close()
    print("Setup complete.")


def main(config_path: str = 'config.yaml'):
    config = load_config(config_path)
    provider = config['provider'].lower()
    if provider == 'digitalocean':
        ip = deploy_digitalocean(config)
    elif provider == 'aws':
        ip = deploy_aws(config)
    else:
        raise ValueError(f"Provider {provider} unsupported")
    time.sleep(60)  # Wait for SSH ready
    setup_vps_via_ssh(ip, config)
    print(f"VPS ready at {ip}. SSH: ssh -i {config['instance']['ssh_key']} ubuntu@{ip}")


if __name__ == "__main__":
    import sys
    main(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')